Please follow the instructions below to test the classifiers.

1. Make sure that the folder 'dataset' is located in the same directory as the folder 'WikipediaVandalismDetection'. We'll call this directory as the root directory.
2. Go to the folder 'helpers' located in the src directory.
3. Run the command: chmod 777 prepare_features.sh
4. Run the command: ./prepare_features.sh. This command prepares the file features.csv in the root directory.
5. Run the command: python prepare_corpus.py. This command prepares the corpus by appending the true label column to the end of features.
6. Go to the folder 'cross_validation' and run the following commands to create the training-testing dataset for the whole corpus. This would create two files in the root directory namely training_set.csv and testing_set.csv.
7. python create_training_validation_test_datasets.py
8. Run the following command to create k-fold training and test datasets on which the hyperparameters would be estimated. This would create 10 files in the root directory as we are selecting k = 5.
9. python k_fold_cross_validation.py
10. Go to the directory 'classifier' and run the following commands to generate files for testing on validation set.
11. python multinomial_naive_bayes.py train
12. python random_forest.py train all (all is used for training on all features)
13. python svm_linear.py train all
14. python svm_rbf.py train all
15. python logistic_regression.py KFOLD to do hyperparameter setting using k-fold cross-validation. The avegare F1 measure is printed on the output for different hyperparameters and visual examination is required to set it.
16. python logistic_regression.py PCA_KFOLD to do hyperparameter setting using 10 principal components as features.
17. python logistic_regression.py TEST (All features used)
18. python logistic_regression.py TEST_PCA (10 principal components used)
19. TRAINING_SET and TESTING_SET global variables in logistic_regression.py to change training and testing files.
17. python one_class_svm.py VALIDATION SVM (Print average F1 measure for all hyperparameters. All features used)
18. python one_class_svm.py VALIDATION ISOLATION_FOREST (Print average F1 measure for hyperparameters. All features used)
19. python one_class_svm.py PCA_VALIDATION SVM (Print average F1 measure for hyperparameters using 10 principal components)
20. python one_class_svm.py PCA_VALIDATION ISOLATION_FOREST (Print average F1 measure for hyperparameters using 10 principal components)
21. python one_class_svm.py TEST SVM
22. python one_class_svm.py TEST ISOLATION_FOREST
******************************************

19. Go to the folder 'helpers' and use the file calculate_hyperparameters to find the best estimate of the parameters of every classifier from the generated txt files in the root directory according to the F1 score.
20. python calculate_hyperparameters.py false
21. Now, test the classifiers on the test dataset test_set.csv using the estimated parameters by running the following commands.
22. python multinomial_naive_bayes.py test 6.5536 (6.5536 is the value of the hyperparameter calculated above)
23. python random_forest.py test 13 15 all (NumTree = 13, MaxDepth = 15)
24. python svm_linear.py test 1 all (C = 1)
25. python svm_rbf.py test 0.01 1000 all (Gamma = 0.01, C = 1000)

****************MOHIT*********************
26. Open the file logistic_regression.py and set the global variables C to the estimated parameter.
27. python logistic_regression.py TEST
28. python one_class_svm.py TEST
******************************************

29. Now, we repeat the above process of training and testing using PCA with 10 components.
30. python random_forest.py train pca (pca is used for training on features selected using PCA)
31. python svm_linear.py train pca
32. python svm_rbf.py train pca

****************MOHIT*********************
33. Insert how to train with PCA in Logistic, One Class and Isolation Forest
******************************************

34. Go to the folder 'helpers' and use the file calculate_hyperparameters to find the best estimate of the parameters of every classifier from the generated txt files in the root directory according to the F1 score.
35. python calculate_hyperparameters.py true
26. Now, test the classifiers on the test dataset test_set.csv using the estimated parameters by running the following commands.
37. python random_forest.py test 9 15 pca (NumTree = 9, MaxDepth = 15)
38. python svm_linear.py test 0.1 pca (C = 0.1)
39. python svm_rbf.py test 0.01 1000 pca (Gamma = 0.01, C = 1000)

****************MOHIT*********************
40. Insert how to test with PCA in Logistic, One Class and Isolation Forest
******************************************
