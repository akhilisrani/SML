Please follow the instructions below to test the classifiers.

1. Make sure that the folder 'dataset' is located in the same directory as the folder 'WikipediaVandalismDetection'. We'll call this directory as the root directory.
2. Go to the folder 'helpers' located in the src directory.
3. Run the command: chmod 777 prepare_features.sh
4. Run the command: ./prepare_features.sh. This command prepares the file features.csv in the root directory.
5. Run the command: python prepare_corpus.py. This command prepares the corpus by appending the true label column to the end of features.
6. Go to the folder 'cross_validation' and run the following commands to create the training-testing dataset for the whole corpus. This would create two files in the root directory namely training_set.csv and testing_set.csv.
7. python create_training_validation_test_datasets.py
8. Run the following command to create k-fold training and test datasets on which the hyperparameters would be estimated. This would create 10 files in the root directory as we are selecting k = 5.
9. python k_fold_cross_validation.py
10. Go to the directory 'classifier' and run the following commands to generate files for testing on validation set.
11. python multinomial_naive_bayes.py train
12. python random_forest.py train all (all is used for training on all features)
13. python svm_linear.py train all
14. python svm_rbf.py train all


****************MOHIT*********************
15. Open the file logistic_regression.py and set the global variables TRAINING_SET, VALIDATION_SET, TESTING_SET to the datasets on which training has to be done.
16. python logistic_regression.py TRAIN
17. Open the file one_class_svm.py and set the global variables TRAINING_SET, VALIDATION_SET, TESTING_SET to the datasets on which training has to be done.
18. python one_class_svm.py TRAIN
******************************************

19. Go to the folder 'helpers' and use the file calculate_hyperparameters to find the best estimate of the parameters of every classifier from the generated txt files in the root directory according to the F1 score.
20. python calculate_hyperparameters.py false
21. Now, test the classifiers on the test dataset test_set.csv using the estimated parameters by running the following commands.
22. python multinomial_naive_bayes.py test 6.5536 (6.5536 is the value of the hyperparameter calculated above)
23. python random_forest.py test 13 15 all (NumTree = 13, MaxDepth = 15)
24. python svm_linear.py test 1 all (C = 1)
25. python svm_rbf.py test 0.01 1000 all (Gamma = 0.01, C = 1000)

****************MOHIT*********************
26. Open the file logistic_regression.py and set the global variables C to the estimated parameter.
27. python logistic_regression.py TEST
28. python one_class_svm.py TEST
******************************************

29. Now, we repeat the above process of training and testing using PCA with 10 components.
30. python random_forest.py train pca (pca is used for training on features selected using PCA)
31. python svm_linear.py train pca
32. python svm_rbf.py train pca

****************MOHIT*********************
33. Insert how to train with PCA in Logistic, One Class and Isolation Forest
******************************************

34. Go to the folder 'helpers' and use the file calculate_hyperparameters to find the best estimate of the parameters of every classifier from the generated txt files in the root directory according to the F1 score.
35. python calculate_hyperparameters.py true
26. Now, test the classifiers on the test dataset test_set.csv using the estimated parameters by running the following commands.
37. python random_forest.py test 9 15 pca (NumTree = 9, MaxDepth = 15)
38. python svm_linear.py test 0.1 pca (C = 0.1)
39. python svm_rbf.py test 0.01 1000 pca (Gamma = 0.01, C = 1000)

****************MOHIT*********************
40. Insert how to test with PCA in Logistic, One Class and Isolation Forest
******************************************
